{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from utils import load_sequence, show_tracked, track_to_file, cossim, load_frame_number\n",
    "from sort.sort import Sort\n",
    "from track import track_sequence\n",
    "from db import DatabaseHandler\n",
    "from feature_extractor import FeatureExtractor\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = 'S01'\n",
    "dir_path = './AICity/train'\n",
    "img_path = './AICity/cam_loc'\n",
    "roi_path = dir_path + '/roi.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_name = 'det/det_tracked.txt'\n",
    "frame_boundaries = load_frame_number(dir_path, seq, det_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1955], [1, 2110], [1, 1996], [1, 2110], [1, 2110]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# det_name_in = 'det/det_yolo3.txt'\n",
    "# track_sequence(dir_path, seq, det_name_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c001', 'c002', 'c003', 'c004', 'c005']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camdirs = os.listdir(os.path.join(dir_path, seq))\n",
    "camdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_captures, img, bboxes = load_sequence(dir_path, img_path, seq, det_name=det_name, with_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq = 'S01'\n",
    "# camdir = 'c001'\n",
    "# det_name_in = 'det/det_tracked.txt'\n",
    "\n",
    "# tracked = get_bboxes(os.path.join(dir_path, seq, camdir, det_name_in), with_id=True)\n",
    "# show_tracked(video_captures[0], tracked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mirun\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mirun\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "dbh = DatabaseHandler('feature_db_2.db')\n",
    "fe = FeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multicamera_tracking(video_captures, bboxes, seq, dbh, fe, camdirs, frame_boundaries, det_name_out='det/det_multi.txt', start_frame=0, end_frame=None):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - video_captures (list): List of videos where each video represents one camera in a sequence.\n",
    "    - bboxes (list): List of dictionaries where each dictionary represents the tracked bounding boxes in one camera.\n",
    "                    Each dictionary includes keys as frame indices and values as bounding box coordinates and track_id.\n",
    "                    Example: [{'frame_1': [[id, x1, y1, x2, y2], [id, x1, y1, x2, y2]], 'frame_2': [[id, x1, y1, x2, y2]]}, ...]\n",
    "    - start_frame (int): The starting frame index for multi-camera tracking. Default is 0.\n",
    "    - end_frame (int): The ending frame index for multi-camera tracking. If None, it tracks until the last frame.\n",
    "                       Default is None.\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "    id_mapping = {}\n",
    "    camdirs = sorted(camdirs)\n",
    "\n",
    "    def get_frame(cap, frame_id):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def process_object(frame, bbox):\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        bbox_img = frame[y1:y2, x1:x2]\n",
    "        bbox_img = Image.fromarray(bbox_img)\n",
    "\n",
    "        return fe.extract_features(bbox_img)\n",
    "\n",
    "    # Iterate over all bboxes to create DB\n",
    "    for cam in range(len(bboxes)):\n",
    "        print(f\"Cam: {cam} so camdir: {camdirs[cam]}\")\n",
    "\n",
    "        frame_id, stop_frame = frame_boundaries[cam]\n",
    "        while frame_id < stop_frame:\n",
    "            print(\"frame \", frame_id)\n",
    "\n",
    "            if not frame_id in bboxes[cam]:\n",
    "                continue \n",
    "\n",
    "            frame_bboxes = bboxes[cam][frame_id]\n",
    "            frame = get_frame(video_captures[cam], frame_id)\n",
    "\n",
    "            for bbox in frame_bboxes:\n",
    "                track_id = bbox[0]\n",
    "\n",
    "                # Do not extract features again if already in DB\n",
    "                if dbh.is_track_id_exists(track_id, seq):\n",
    "                    continue\n",
    "\n",
    "                # Extract feature of object in bbox and save to DB\n",
    "                feature_vector = process_object(frame, bbox[1:])\n",
    "                dbh.insert_feature(track_id, frame_id, seq, cam, feature_vector, False)\n",
    "\n",
    "            frame_id += 1\n",
    "\n",
    "    print(f\"---------------------------------------\")\n",
    "\n",
    "    \n",
    "    # Iterate over all cameras to reidentify    \n",
    "    for cam in range(len(bboxes)):\n",
    "        print(f\"Cam: {cam} so camdir: {camdirs[cam]}\")\n",
    "\n",
    "        frame_id, stop_frame = frame_boundaries[cam]\n",
    "        bboxes_out = {}\n",
    "\n",
    "        print(f\"Frame ID: {frame_id} stop_frame: {stop_frame}\")\n",
    "        while frame_id < stop_frame:\n",
    "            print(\"frame \", frame_id)\n",
    "\n",
    "            if not frame_id in bboxes[cam]:\n",
    "                continue \n",
    "            \n",
    "            # Get the bounding boxes in given camera and at certain frame\n",
    "            frame_bboxes = bboxes[cam][frame_id]\n",
    "            frame = get_frame(video_captures[cam], frame_id)\n",
    "\n",
    "            for bbox in frame_bboxes:\n",
    "                track_id = bbox[0]\n",
    "\n",
    "                # Extract feature of object in bbox\n",
    "                feature_vector = process_object(frame, bbox[1:])\n",
    "\n",
    "                # Perform similarity search if new tracking_id (not in DB)\n",
    "                curr_obj = dbh.get_object(track_id, seq)\n",
    "\n",
    "                # Check that this object has not be reidentified already\n",
    "                if curr_obj and not curr_obj[-1]:\n",
    "                    # TODO: Add offset according to timestamp \n",
    "                    # The issue might be that the first time an object is tracked is way before\n",
    "                    # it appears in another video\n",
    "                    objects = dbh.get_between_frames_not_in_camera(frame_id - 50, frame_id + 50, camdirs[cam])\n",
    "                    max_similarity, max_id = 0, -1\n",
    "                    for obj in objects:\n",
    "                        obj_fv = np.frombuffer(obj[-1], dtype=np.float32)\n",
    "\n",
    "                        similarity = cossim(obj_fv, feature_vector)\n",
    "                        if similarity > max_similarity:\n",
    "                            max_similarity, max_id = similarity, obj[0]\n",
    "\n",
    "                    if max_similarity > 0.85:\n",
    "                        # Mark object as reidentified\n",
    "                        dbh.update_reid(track_id, seq, True)\n",
    "\n",
    "                        # Ensure that the objects do not map to each other\n",
    "                        if max_id in id_mapping and id_mapping[max_id] != track_id:\n",
    "                            print(f\"{track_id} mapped to {max_id} with {max_similarity} confidence\")\n",
    "                            id_mapping[track_id] = max_id\n",
    "\n",
    "\n",
    "                reid = id_mapping[track_id] if track_id in id_mapping else track_id\n",
    "                if frame_id not in bboxes_out:\n",
    "                    bboxes_out[frame_id] = []\n",
    "                \n",
    "                bboxes_out[frame_id].append((frame_id, bbox[1], bbox[2], bbox[3], bbox[4], reid))\n",
    "            frame_id += 1\n",
    "\n",
    "        camdir = camdirs[cam]\n",
    "        track_to_file(bboxes_out, os.path.join(dir_path, seq, camdir, det_name_out))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n",
      "2048\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmulticamera_tracking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_captures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdbh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcamdirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_boundaries\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 48\u001b[0m, in \u001b[0;36mmulticamera_tracking\u001b[1;34m(video_captures, bboxes, seq, dbh, fe, camdirs, frame_boundaries, det_name_out, start_frame, end_frame)\u001b[0m\n\u001b[0;32m     45\u001b[0m             feature_vector \u001b[38;5;241m=\u001b[39m process_object(frame, bbox[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m     46\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(feature_vector))\n\u001b[1;32m---> 48\u001b[0m             \u001b[43mdbh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrack_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m         frame_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Iterate over all cameras to reidentify    \u001b[39;00m\n",
      "File \u001b[1;32md:\\UNI\\MSC\\C6\\Projects\\c6-personal-repo\\week4\\db.py:22\u001b[0m, in \u001b[0;36mDatabaseHandler.insert_feature\u001b[1;34m(self, track_id, frame_id, seq, cam, feature_vector, reid)\u001b[0m\n\u001b[0;32m     19\u001b[0m feature_vector_bytes \u001b[38;5;241m=\u001b[39m feature_vector\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcursor\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINSERT INTO features VALUES (?, ?, ?, ?, ?, ?)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m                     (track_id, frame_id, seq, cam, feature_vector_bytes, reid))\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "multicamera_tracking(video_captures, bboxes, seq, dbh, fe, camdirs, frame_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
